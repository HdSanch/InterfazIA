[{"chunk_id": "c0", "text": "# RAG NotebookLM-like (Gemini) — Backend + UI mínima\n\nProyecto tipo RAG inspirado en NotebookLM: el usuario sube un documento y el sistema:\n- Indexa el contenido en fragmentos (chunks)\n- Permite chatear con el documento (RAG)\n- Genera un resumen\n- Genera un plan de estudio\n- Genera preguntas de práctica y corrige respuestas usando evidencia del documento\n\nEl enfoque es híbrido:\n- Recuperación **lexical** con TF-IDF\n- Recuperación **semántica** con embeddings y FAISS\n- Respuesta generada con **Gemini** usando el contexto recuperado (con citas por chunk)\n\n---\n\n## Estructura del repositorio\n\n```text\nrag-notebooklm-like/\nbackend/\napp/\nmain.py\ncore/\nconfig.py\napi/\nroutes/\ndocuments.py\nchat.py\noutputs.py\nschemas/\ncommon.py\nservices/\ningest/\nloaders.py\nchunker.py\nindex/\nlexical.py\nvectorstore.py\nllm/\ngemini_client.py\nrag/\npipeline.py\nstorage/\nuploads/\ndocs/\nindexes/\nrequirements.txt\nrequirement", "start": 0, "end": 900}, {"chunk_id": "c1", "text": "rs.py\nchunker.py\nindex/\nlexical.py\nvectorstore.py\nllm/\ngemini_client.py\nrag/\npipeline.py\nstorage/\nuploads/\ndocs/\nindexes/\nrequirements.txt\nrequirements-dev.txt\n.env.example\ntests/\nconftest.py\nunit/\ntest_chunker.py\ntest_lexical.py\ntest_vectorstore.py\ntest_rag_prompt.py\ntest_loaders_docx.py\ntest_loaders_txt_md.py\nintegration/\ntest_chat_endpoint.py\ntest_documents_upload.py\ntest_outputs_endpoints.py\ntest_practice_endpoints.py\nweb_min/\nindex.html\napp.js\nREADME.md", "start": 750, "end": 1212}]